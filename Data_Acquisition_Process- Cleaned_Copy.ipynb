{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Your Data From Yelp!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure you are on track to completing the project, you will complete this workbook first. Below are steps that you need to take in order to make sure you have your data from yelp and are ready to analyze it. Your cohort lead will review this workbook with you the Wednesday before your project is due.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Part 1 - Understanding your data and question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You will be pulling data from the Yelp API to complete your analysis. The API, however, provides you with a lot of information that will not be pertinent to your analysis. You will pull data from the API and parse through it to keep only the data that you will need. In order to help you identify that information,look at the API documentation and understand what data the API will provide you. \n",
    "\n",
    "Identify which data fields you will want to keep for your analysis. \n",
    "\n",
    "https://www.yelp.com/developers/documentation/v3/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Create ETL pipeline for the business data from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that you know what data you need from the API, you want to write code that will execute an API call, parse those results and then insert the results into the DB.  \n",
    "\n",
    "It is helpful to break this up into three different functions (*API call, parse results, and insert into DB*) and then you can write a function/script that pull the other three functions together. \n",
    "\n",
    "Let's first do this for the Business endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:47.178017Z",
     "start_time": "2021-05-11T23:14:46.123014Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\bmcca\\\\.secret\\\\yelp_api.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-09d10917c5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\bmcca\\.secret\\yelp_api.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\bmcca\\\\.secret\\\\yelp_api.json'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "with open(r'C:\\Users\\jax\\.secret\\creds.json') as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "client_id = keys['id']\n",
    "yelp_key = keys['key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Æ’: yelp_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T15:58:43.341776Z",
     "start_time": "2021-05-10T15:58:43.321768Z"
    }
   },
   "source": [
    " - Params: search term (eg. \"wineries); location; yelp_key variable (from Imports); and changing setting to print details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:47.225012Z",
     "start_time": "2021-05-11T23:14:47.211011Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def yelp_request(term, location, yelp_key, verbose=True):\n",
    "    '''Adapted from Yelp API Lab: https://github.com/BenJMcCarty/dsc-yelp-api-lab/tree/solution'''\n",
    "    \n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "    headers = {\n",
    "            'Authorization': 'Bearer {}'.format(yelp_key),\n",
    "        }\n",
    "\n",
    "    url_params = {\n",
    "                    'term': term.replace(' ', '+'),\n",
    "                    'location': location.replace(' ', '+'),\n",
    "                    'limit': 50\n",
    "                }\n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(response)\n",
    "        print(type(response.text))\n",
    "        print(response.text[:1000])\n",
    "        \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:44:09.881783Z",
     "start_time": "2021-05-10T19:44:09.868735Z"
    }
   },
   "source": [
    "### Sending the request and saving the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un-comment the next line to run the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:48.566011Z",
     "start_time": "2021-05-11T23:14:47.945014Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = yelp_request('winery','Southern California', yelp_key)\n",
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:43:06.445686Z",
     "start_time": "2021-05-10T19:43:06.434686Z"
    }
   },
   "source": [
    "#### Saving/Loading as JSON for simplicity while iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:48.613016Z",
     "start_time": "2021-05-11T23:14:48.599012Z"
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     with open(r'data\\response.txt', 'w') as f:\n",
    "#         json.dump(response, f)\n",
    "# except IOError:\n",
    "#     print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:49.000012Z",
     "start_time": "2021-05-11T23:14:48.990014Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/response.txt') as json_file:\n",
    "#     data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Exploring Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:50.259028Z",
     "start_time": "2021-05-11T23:14:50.245014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify keys\n",
    "\n",
    "print(response.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the \"Businesses\" Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:51.179014Z",
     "start_time": "2021-05-11T23:14:51.110015Z"
    }
   },
   "outputs": [],
   "source": [
    "response['businesses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:51.597013Z",
     "start_time": "2021-05-11T23:14:51.584013Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show first item w/in list of businesses\n",
    "\n",
    "response['businesses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:52.051012Z",
     "start_time": "2021-05-11T23:14:52.029014Z"
    }
   },
   "outputs": [],
   "source": [
    "response['businesses'][0]['categories'][0]['alias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:52.441014Z",
     "start_time": "2021-05-11T23:14:52.432013Z"
    }
   },
   "outputs": [],
   "source": [
    "response['businesses'][0]['categories'][0]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the \"Total\" Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:53.129012Z",
     "start_time": "2021-05-11T23:14:53.109012Z"
    }
   },
   "outputs": [],
   "source": [
    "response['total']\n",
    "\n",
    "# How many businesses are there in total for my request?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the \"Region\" Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:53.962014Z",
     "start_time": "2021-05-11T23:14:53.942017Z"
    }
   },
   "outputs": [],
   "source": [
    "response['region']\n",
    "\n",
    "# From which geographical area will my results come?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:14:54.772016Z",
     "start_time": "2021-05-11T23:14:54.759022Z"
    }
   },
   "outputs": [],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:41:29.180856Z",
     "start_time": "2021-05-10T21:41:29.173856Z"
    }
   },
   "source": [
    "### Æ’: parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:28.194041Z",
     "start_time": "2021-05-11T23:15:28.182017Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def parse_data(list_of_data):\n",
    "    '''Adapted from Tyrell's code'''  \n",
    "\n",
    "    # Create empty list to store results\n",
    "    \n",
    "    parsed_data = []\n",
    "    \n",
    "    # Loop through each business in the list of businesses\n",
    "    # Add specific k:v pairs to a dictionary\n",
    "    # These pairs will be used to build a DF afterwards\n",
    "    \n",
    "    for business in list_of_data:\n",
    "        if 'price' not in business:\n",
    "            business['price'] = np.nan\n",
    "            \n",
    "            # Verify that the \"price\" key is in the selected business dict\n",
    "            \n",
    "        details = {'name': business['name'],\n",
    "                     'location': ' '.join(business['location']['display_address']),\n",
    "                     'id': business['id'],\n",
    "                     #'categories': business['categories'],\n",
    "                     'alias': business['categories'][0]['alias'],\n",
    "                     'title': business['categories'][0]['title'],\n",
    "                     'rating': business['rating'],\n",
    "                     'review_count': business['review_count'],\n",
    "                     'price': business['price'],\n",
    "                     'latitude': business['coordinates']['latitude'],\n",
    "                     'longitude': business['coordinates']['longitude']\n",
    "                    }\n",
    "\n",
    "        # If the \"price\" key is missing, then skip adding that key\n",
    "        # This avoids an error when getting the desired info\n",
    "        \n",
    "#         else:\n",
    "#             details = {'name': business['name'],\n",
    "#                          'location': business['location']['display_address'],\n",
    "#                          'id': business['id'],\n",
    "#                          #'categories': business['categories'],\n",
    "#                          'alias': business['categories'][0]['alias'],\n",
    "#                          'title': business['categories'][0]['title'],\n",
    "#                          'rating': business['rating'],\n",
    "#                          'review_count': business['review_count'],\n",
    "#                          'latitude': business['coordinates']['latitude'],\n",
    "#                          'longitude': business['coordinates']['longitude']\n",
    "#                         }\n",
    "        \n",
    "        # Add the new dictionary to the previous list\n",
    "        \n",
    "        parsed_data.append(details)\n",
    "    \n",
    "    # Adjust the 'location' value to be a single string (not 2 str in a list)\n",
    "    \n",
    "#     for biz in parsed_data:\n",
    "#         biz['location'] = ' '.join(biz['location'])\n",
    "        \n",
    "    # Create a DataFrame from the resulting list\n",
    "    \n",
    "    df_parsed_data = pd.DataFrame(parsed_data)\n",
    "    \n",
    "#     df_parsed_data.dropna(inplace=True)\n",
    "    \n",
    "    return df_parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:28.630016Z",
     "start_time": "2021-05-11T23:15:28.572016Z"
    }
   },
   "outputs": [],
   "source": [
    "parsed_results = parse_data(response['businesses'])\n",
    "parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:29.382043Z",
     "start_time": "2021-05-11T23:15:29.367015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify totals of NaN values\n",
    "\n",
    "parsed_results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:29.939009Z",
     "start_time": "2021-05-11T23:15:29.910012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple statistical exploration of quantitative values\n",
    "\n",
    "parsed_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:37:53.049725Z",
     "start_time": "2021-05-10T22:37:53.042727Z"
    }
   },
   "source": [
    "## Updating Requests for Pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Æ’: yelp_request_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:39.021396Z",
     "start_time": "2021-05-11T23:15:39.015399Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def yelp_request_offset(term, location, yelp_key, offset=0, verbose=False):\n",
    "    '''Adapted from Yelp API Lab: https://github.com/BenJMcCarty/dsc-yelp-api-lab/tree/solution'''\n",
    "    \n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "    headers = {\n",
    "            'Authorization': 'Bearer {}'.format(yelp_key),\n",
    "        }\n",
    "\n",
    "    url_params = {\n",
    "                    'term': term.replace(' ', '+'),\n",
    "                    'location': location.replace(' ', '+'),\n",
    "                    'limit': 50,\n",
    "                    'offset': offset\n",
    "                        }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(response)\n",
    "        print(type(response.text))\n",
    "        print(response.text[:1000])\n",
    "        \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T21:52:21.177479Z",
     "start_time": "2021-05-10T21:52:21.167481Z"
    }
   },
   "source": [
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:40.863394Z",
     "start_time": "2021-05-11T23:15:40.006398Z"
    }
   },
   "outputs": [],
   "source": [
    "test1 = yelp_request_offset('winery', 'San Diego', yelp_key, offset=0, verbose=False)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:40.941394Z",
     "start_time": "2021-05-11T23:15:40.928394Z"
    }
   },
   "outputs": [],
   "source": [
    "test1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:41.019393Z",
     "start_time": "2021-05-11T23:15:41.005393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:41.626392Z",
     "start_time": "2021-05-11T23:15:41.610395Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test1['businesses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:44.693427Z",
     "start_time": "2021-05-11T23:15:43.194399Z"
    }
   },
   "outputs": [],
   "source": [
    "test2 = yelp_request_offset('winery', 'San Diego', yelp_key, offset=50, verbose=False)\n",
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:45.470392Z",
     "start_time": "2021-05-11T23:15:44.761397Z"
    }
   },
   "outputs": [],
   "source": [
    "results = yelp_request_offset('winery', 'San Diego', yelp_key, offset=0, verbose=False)\n",
    "\n",
    "num_pages = results['total']//50+1\n",
    "\n",
    "print(results['total'])\n",
    "print(len(results['businesses']))\n",
    "print(num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:57.500392Z",
     "start_time": "2021-05-11T23:15:54.294398Z"
    }
   },
   "outputs": [],
   "source": [
    "cur = 50\n",
    "parsed_results_dfs = []\n",
    "\n",
    "for num in range(num_pages):\n",
    "    results = yelp_request_offset('winery', 'San Diego', yelp_key, offset=cur, verbose=False)\n",
    "    parsed_results = parse_data(results['businesses'])\n",
    "    parsed_results_dfs.append(parsed_results)\n",
    "    cur += 50\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:15:57.703394Z",
     "start_time": "2021-05-11T23:15:57.643395Z"
    }
   },
   "outputs": [],
   "source": [
    "parsed_results_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:16:01.793395Z",
     "start_time": "2021-05-11T23:16:01.765397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_concat = pd.concat(parsed_results_dfs, ignore_index=True)\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Æ’: df_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parsed results to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.300219Z",
     "start_time": "2021-05-11T20:54:27.341Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.301218Z",
     "start_time": "2021-05-11T20:54:27.347Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_concat.to_csv('data\\wineries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.303220Z",
     "start_time": "2021-05-11T20:54:27.353Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/wineries.csv\", index_col=0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Old Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.304219Z",
     "start_time": "2021-05-11T20:54:27.357Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from helper_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.306219Z",
     "start_time": "2021-05-11T20:54:27.362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # create a variable  to keep track of which result you are in. \n",
    "# cur = 0\n",
    "\n",
    "# #set up a while loop to go through and grab the result \n",
    "# while cur < num and cur < 1000:\n",
    "#     #set the offset parameter to be where you currently are in the results \n",
    "\n",
    "#     #make your API call with the new offset number\n",
    "#     results = yelp_call_offset('winery', 'San Diego', yelp_key, offset=cur, verbose=False)\n",
    "    \n",
    "#     #after you get your results you can now use your function to parse those results\n",
    "#     parsed_results = parse_results(results)\n",
    "    \n",
    "#     # use your function to insert your parsed results into the db\n",
    "#     df_save(parsed_results)\n",
    "#     #increment the counter by 50 to move on to the next results\n",
    "#     cur += 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit and Condense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: condense the details down to specific functions (perhaps one function?) to pull, clean, and save data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it will take some experimentation to write the functions above, once you get them working it will be best to put them in a `.py` file and then import the functions to use in a script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Æ’: GET FULL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.307218Z",
     "start_time": "2021-05-11T20:54:27.369Z"
    }
   },
   "outputs": [],
   "source": [
    "# results = yelp_request_offset('winery', 'San Diego', yelp_key, offset=0, verbose=False)\n",
    "\n",
    "# num_pages = results['total']//50+1\n",
    "\n",
    "# print(results['total'])\n",
    "# print(len(results['businesses']))\n",
    "# print(num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:17:51.328250Z",
     "start_time": "2021-05-11T23:17:51.309257Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_full_data(term, location, yelp_key, file_name = 'data/wineries.csv'):\n",
    "    '''Requests all results from Yelp API; saves as a .csv; and returns a DataFrame.'''\n",
    "    blank_df = pd.DataFrame()\n",
    "    blank_df.to_csv(file_name)\n",
    "    \n",
    "    # Process first request to Yelp API and calculate number of pages \n",
    "    results = yelp_request_offset(term, location, yelp_key, offset=0, verbose=False)\n",
    "    num_pages = results['total']//50+1\n",
    "    \n",
    "    # Print out confirmation feedback\n",
    "    print(f'For {term} and {location}: ')\n",
    "    print(f\"    Total number of results: {results['total']}.\")\n",
    "    print(f'    Total number of pages: {num_pages}.')\n",
    "    \n",
    "    # Create offset for further results and create empty list\n",
    "    cur = 0\n",
    "    parsed_results_dfs = []\n",
    "\n",
    "    # Retrieves remaining pages\n",
    "    for num in range(num_pages-1):\n",
    "        try:\n",
    "            results = yelp_request_offset(term, location, yelp_key, offset=cur, verbose=False)\n",
    "            parsed_results = parse_data(results['businesses'])\n",
    "            parsed_results_dfs.append(parsed_results)\n",
    "            cur += 50\n",
    "        except:\n",
    "            print(f'Error on page {num}.')\n",
    "            parsed_results_dfs.to_csv(file_name, mode='a')\n",
    "\n",
    "    # Concatenate DataFrames and save to .csv\n",
    "    df_concat = pd.concat(parsed_results_dfs, ignore_index=True)\n",
    "\n",
    "    try:\n",
    "        df_concat.to_csv(file_name)\n",
    "        print(f'Saved to {file_name}.')\n",
    "    except:\n",
    "        print(f'Error, did not save.')\n",
    "        \n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:17:58.179247Z",
     "start_time": "2021-05-11T23:17:53.848248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = get_full_data('winery', 'San Diego', yelp_key)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.312221Z",
     "start_time": "2021-05-11T20:54:27.380Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(df2['name'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.314218Z",
     "start_time": "2021-05-11T20:54:27.383Z"
    }
   },
   "outputs": [],
   "source": [
    "# df3 = get_full_data('pizza', 'Baltimore', yelp_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.316219Z",
     "start_time": "2021-05-11T20:54:27.386Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.317218Z",
     "start_time": "2021-05-11T20:54:27.390Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T20:54:28.319218Z",
     "start_time": "2021-05-11T20:54:27.399Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2[df2['price'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying top 3 aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:20:12.342277Z",
     "start_time": "2021-05-11T23:20:12.328271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new DF showing only alias and title columns\n",
    "df2_alias = df2.loc[:,['alias', 'title']]\n",
    "\n",
    "# Identify top 2 aliases \n",
    "df2_alias_count = df2_alias.groupby('alias').count().sort_values(['title'],\\\n",
    "                                                        ascending=False)[:2]\n",
    "df2_alias_count.reset_index(inplace=True)\n",
    "\n",
    "print(df2_alias_count)\n",
    "\n",
    "# display them as a list\n",
    "aliases_top_3 = df2_alias_count['alias'].tolist()\n",
    "print(aliases_top_3)\n",
    "\n",
    "# Note: initially tried top 3, but it returned distributors, not wineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:20:35.248384Z",
     "start_time": "2021-05-11T23:20:35.206383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting rows based on condition\n",
    "\n",
    "df3 = df2[df2['alias'].isin(aliases_top_3)]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:20:52.118035Z",
     "start_time": "2021-05-11T23:20:52.095036Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.to_csv('data/filtered_aliases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:20:52.588035Z",
     "start_time": "2021-05-11T23:20:52.545036Z"
    }
   },
   "outputs": [],
   "source": [
    "df_saved = pd.read_csv(\"data/filtered_aliases.csv\", index_col=0)\n",
    "df_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore - old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:21:09.492036Z",
     "start_time": "2021-05-11T23:21:09.485036Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df2_alias_sorted = df2_alias_count.sort_values(['title'], ascending=False)\n",
    "# df3_alias = pd.DataFrame(df2_alias_sorted)\n",
    "# df3_alias\n",
    "\n",
    "# df3_alias.groupby('alias').sum().sort_values(['title'], ascending=False)[:3]\n",
    "\n",
    "# df_alias_top_3 = df3_alias.loc[:, 'title']#[:3]\n",
    "# df_alias_top_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:21:09.897037Z",
     "start_time": "2021-05-11T23:21:09.885036Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2_alias = df2.loc[:,'alias']\n",
    "\n",
    "# df2_alias_count = df2.groupby('alias').count()#.sort_values(['alias'], ascending=False)#[:3]\n",
    "# df2_alias_count.reset_index(inplace=True)\n",
    "\n",
    "# df2_alias_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 -  Create ETL pipeline for the restaurant review data from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've done this for the Businesses, now you need to do this for reviews. You will follow the same process, but your functions will be specific to reviews. Above you have a model of the functions you will need to write, and how to pull them together in one script. For this part, you have the process below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Business IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to pull the reveiws, you will need the business ids. So your first step will be to get all of the business ids from your businesses csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open file and slice ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open data/wineries.csv\n",
    "2. Slice out the 'name' and 'id' columns for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:21:11.382037Z",
     "start_time": "2021-05-11T23:21:11.337034Z"
    }
   },
   "outputs": [],
   "source": [
    "df_saved = pd.read_csv(\"data/filtered_aliases.csv\", index_col=0)\n",
    "df_saved.reset_index(drop=True, inplace=True)\n",
    "df_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:21:15.015032Z",
     "start_time": "2021-05-11T23:21:15.004037Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Slice out the elements from the \"name\" column\n",
    "\n",
    "df_saved_name = df_saved['name'].to_list()\n",
    "df_saved_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:21:37.643035Z",
     "start_time": "2021-05-11T23:21:37.629045Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_saved_id = df_saved['id'].to_list()\n",
    "df_saved_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function that takes a business id and makes a call to the API for reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Æ’: yelp_id_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:22:39.787035Z",
     "start_time": "2021-05-11T23:22:39.770036Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing how to create URL properly for API request\n",
    "\n",
    "biz_id = \"DknnpiG1p4OoM1maFshzXA\"\n",
    "url = 'https://api.yelp.com/v3/businesses/' + biz_id + '/reviews'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:22:40.698035Z",
     "start_time": "2021-05-11T23:22:40.683034Z"
    }
   },
   "outputs": [],
   "source": [
    "# f'https /{biz_id}/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:23:39.095977Z",
     "start_time": "2021-05-11T23:23:39.079978Z"
    }
   },
   "outputs": [],
   "source": [
    "# for biz in biz_ids:\n",
    "#     reviews = reviewcall(biz)\n",
    "#     parsed_reviews = parse_reviews(reviews, biz)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:23:44.974976Z",
     "start_time": "2021-05-11T23:23:44.958978Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def yelp_id_offset(biz_id, yelp_key, offset=0, verbose=True):\n",
    "    '''Adapted from Yelp API Lab: https://github.com/BenJMcCarty/dsc-yelp-api-lab/tree/solution'''\n",
    "    \n",
    "    url = 'https://api.yelp.com/v3/businesses/'+ f'{biz_id}' + '/reviews'\n",
    "\n",
    "    headers = {\n",
    "            'Authorization': 'Bearer {}'.format(yelp_key),\n",
    "        }\n",
    "\n",
    "    url_params = {\n",
    "#                     'id': biz_id.replace(' ', '+'),\n",
    "                    'limit': 50,\n",
    "                    'offset': offset\n",
    "                        }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(response)\n",
    "        print(type(response.text))\n",
    "        print(response.text[:1000])\n",
    "        \n",
    "        \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ID Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:24:14.884974Z",
     "start_time": "2021-05-11T23:24:14.864977Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(len(reviews1['reviews']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore Reviews1 Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:34:01.728650Z",
     "start_time": "2021-05-11T23:34:01.722652Z"
    }
   },
   "outputs": [],
   "source": [
    "# reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:34:05.960653Z",
     "start_time": "2021-05-11T23:34:05.947652Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(type(reviews_list['reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:34:16.956651Z",
     "start_time": "2021-05-11T23:34:16.952661Z"
    }
   },
   "outputs": [],
   "source": [
    "# reviews1['reviews'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:34:21.320661Z",
     "start_time": "2021-05-11T23:34:21.303654Z"
    }
   },
   "outputs": [],
   "source": [
    "# reviews1['reviews'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:34:23.926653Z",
     "start_time": "2021-05-11T23:34:23.910654Z"
    }
   },
   "outputs": [],
   "source": [
    "# reviews1['reviews'][0]['user']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Æ’: Parse_Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:49:51.807111Z",
     "start_time": "2021-05-11T23:49:51.796107Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def parse_reviews(list_of_reviews):\n",
    "    '''Adapted from Tyrell's code'''  \n",
    "\n",
    "    # Create empty list to store results\n",
    "    \n",
    "    parsed_reviews = []\n",
    "    \n",
    "    # Loop through each review in the list of reviews\n",
    "    # Add specific k:v pairs to a dictionary\n",
    "    # These pairs will be used to build a DF afterwards\n",
    "    \n",
    "#     print('Completed: create list ' + f'{parsed_reviews}')\n",
    "    \n",
    "    for review in list_of_reviews:\n",
    "        details = {'Reviewer Name': review['user']['name'],\n",
    "            'Review ID': review['id'],\n",
    "            'Time Created': review['time_created'],\n",
    "            'Review Rating': review['rating'],\n",
    "            'Review Text': review['text']\n",
    "            }\n",
    "        \n",
    "        # Add the new dictionary to the empty list\n",
    "        \n",
    "        parsed_reviews.append(details)\n",
    "    \n",
    "#     print('Completed: append list')\n",
    "    \n",
    "    # Create a DataFrame from the resulting list\n",
    "    \n",
    "    df_parsed_reviews = pd.DataFrame(parsed_reviews)\n",
    "\n",
    "#     print('Created DF')\n",
    "    \n",
    "    return df_parsed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T23:49:52.326104Z",
     "start_time": "2021-05-11T23:49:52.318109Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_parsed_reviews = parse_reviews(reviews1['reviews'])\n",
    "# # df_parsed_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Æ’: Get_Full_Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:04:43.371255Z",
     "start_time": "2021-05-12T00:04:43.354245Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_reviews(biz_id, yelp_key,verbose=False):\n",
    "    '''Requests all results from Yelp API; saves as a .csv; and returns a DataFrame.'''\n",
    "    \n",
    "    # Process first request to Yelp API and calculate number of pages \n",
    "    results = yelp_id_offset(biz_id, yelp_key, offset=0, verbose=False)\n",
    "    num_pages = results['total']//50+1\n",
    "    \n",
    "    # Print out confirmation feedback\n",
    "    if verbose == True:\n",
    "        print(f'For {biz_id}: ')\n",
    "        print(f\"    Total number of results: {results['total']}.\")\n",
    "        print(f'    Total number of pages: {num_pages}.')\n",
    "    \n",
    "    # Create offset for further results and create empty list\n",
    "    cur = len(results['reviews'])\n",
    "    parsed_results_dfs = []\n",
    "\n",
    "    # Retrieves remaining pages\n",
    "    for num in range(1,num_pages):\n",
    "        try:\n",
    "            results = yelp_id_offset(biz_id, yelp_key, offset=cur, verbose=False)\n",
    "            parsed_results = parse_reviews(results['reviews'])\n",
    "            parsed_results['Business ID'] = biz_id\n",
    "            parsed_results_dfs.append(parsed_results)\n",
    "            cur += len(results['reviews'])\n",
    "        except Exception as e:\n",
    "            print(f'Error on page {num}.')\n",
    "            print(e)\n",
    "\n",
    "    # Concatenate DataFrames and save to .csv\n",
    "    try:\n",
    "        df_concat = pd.concat(parsed_results_dfs, ignore_index=True)\n",
    "        df_concat.to_csv('data/business_ids.csv')\n",
    "        return df_concat\n",
    "    except Exception as e:\n",
    "        print(f'Error, did not concat.')\n",
    "        print(e)\n",
    "#         return parsed_results_dfs\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         df_concat.to_csv('data/business_ids.csv')\n",
    "# #         print(f'Saved to data/business_ids.csv.')\n",
    "#     except:\n",
    "#         print(f'Error, did not save.')\n",
    "        \n",
    "#     return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:01:34.667633Z",
     "start_time": "2021-05-12T00:01:33.335039Z"
    }
   },
   "outputs": [],
   "source": [
    "biz_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:01:34.977631Z",
     "start_time": "2021-05-12T00:01:34.966635Z"
    }
   },
   "outputs": [],
   "source": [
    "# results = yelp_id_offset(biz_id, yelp_key, offset=0, verbose=False)\n",
    "# num_pages = 2 #results['total']//50+1\n",
    "\n",
    "# # Print out confirmation feedback\n",
    "# print(f'For {biz_id}: ')\n",
    "# print(f\"    Total number of results: {results['total']}.\")\n",
    "# print(f'    Total number of pages: {num_pages}.')\n",
    "\n",
    "# # Create offset for further results and create empty list\n",
    "# cur = 50\n",
    "# parsed_results_dfs = []\n",
    "\n",
    "# # Retrieves remaining pages\n",
    "# for num in range(num_pages-1):\n",
    "#     try:\n",
    "#         results = yelp_id_offset(biz_id, yelp_key, offset=cur, verbose=False)\n",
    "#         parsed_results = parse_reviews(results['reviews'])\n",
    "#         parsed_results_dfs.append(parsed_results)\n",
    "#         cur += 50\n",
    "#     except Exception as e:\n",
    "#         print(f'Error on page {num}.')\n",
    "#         print(e)\n",
    "\n",
    "# # Concatenate DataFrames and save to .csv\n",
    "# df_concat = pd.concat(parsed_results_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:03:27.530213Z",
     "start_time": "2021-05-12T00:02:36.135548Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_list = []\n",
    "\n",
    "for biz_id in df_saved_id:\n",
    "    review_result = get_reviews(biz_id, yelp_key)\n",
    "    if review_result is not None:\n",
    "        reviews_list.append(review_result)\n",
    "\n",
    "reviews_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T00:03:27.939213Z",
     "start_time": "2021-05-12T00:03:27.895213Z"
    }
   },
   "outputs": [],
   "source": [
    "df_reviews = pd.concat(reviews_list, ignore_index=True)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to parse out the relevant information from the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust prior function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T01:01:23.493381Z",
     "start_time": "2021-05-11T01:01:23.481209Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def parse_data(list_of_data):\n",
    "#     '''Adapted from Tyrell's code'''  \n",
    "\n",
    "\n",
    "#     parsed_data = []\n",
    "     \n",
    "#     for business in list_of_data:\n",
    "#         if 'price' in business:\n",
    "#             details = {'name': business['name'],\n",
    "#                          'location': business['location']['display_address'],\n",
    "#                          'id': business['id'],\n",
    "#                          #'categories': business['categories'],\n",
    "#                          'alias': business['categories'][0]['alias'],\n",
    "#                          'title': business['categories'][0]['title'],\n",
    "#                          'rating': business['rating'],\n",
    "#                          'review_count': business['review_count'],\n",
    "#                          'price': business['price'],\n",
    "#                          'latitude': business['coordinates']['latitude'],\n",
    "#                          'longitude': business['coordinates']['longitude']\n",
    "#                         }\n",
    "#         else:\n",
    "#             details = {'name': business['name'],\n",
    "#                          'location': business['location']['display_address'],\n",
    "#                          'id': business['id'],\n",
    "#                          #'categories': business['categories'],\n",
    "#                          'alias': business['categories'][0]['alias'],\n",
    "#                          'title': business['categories'][0]['title'],\n",
    "#                          'rating': business['rating'],\n",
    "#                          'review_count': business['review_count'],\n",
    "#                          'latitude': business['coordinates']['latitude'],\n",
    "#                          'longitude': business['coordinates']['longitude']\n",
    "#                         }\n",
    "    \n",
    "#         parsed_data.append(details)\n",
    "    \n",
    "#     for biz in parsed_data:\n",
    "#         biz['location'] = ' '.join(biz['location'])\n",
    "        \n",
    "#     df_parsed_data = pd.DataFrame(parsed_data)\n",
    "    \n",
    "# #     df_parsed_data.dropna(inplace=True)\n",
    "    \n",
    "#     return df_parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Parsed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to save the parse data into a csv file containing all of the reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust function to save to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T01:00:59.613284Z",
     "start_time": "2021-05-11T01:00:59.596732Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def get_full_data(term, location, yelp_key, file_name = 'data/wineries.csv'):\n",
    "#     '''Requests all results from Yelp API; saves as a .csv; and returns a DataFrame.'''\n",
    "    \n",
    "#     # Process first request to Yelp API and calculate number of pages \n",
    "#     results = yelp_request_offset(term, location, yelp_key, offset=0, verbose=False)\n",
    "#     num_pages = results['total']//50+1\n",
    "    \n",
    "#     # Print out confirmation feedback\n",
    "#     print(f'For {term} and {location}: ')\n",
    "#     print(f\"    Total number of results: {results['total']}.\")\n",
    "#     print(f'    Total number of pages: {num_pages}.')\n",
    "    \n",
    "#     # Create offset for further results and create empty list\n",
    "#     cur = 50\n",
    "#     parsed_results_dfs = []\n",
    "\n",
    "#     # Retrieves remaining pages\n",
    "#     for num in range(num_pages-1):\n",
    "#         try:\n",
    "#             results = yelp_request_offset(term, location, yelp_key, offset=cur, verbose=False)\n",
    "#             parsed_results = parse_data(results['businesses'])\n",
    "#             parsed_results_dfs.append(parsed_results)\n",
    "#             cur += 50\n",
    "#         except:\n",
    "#             print(f'Error on page {num}.')\n",
    "\n",
    "#     # Concatenate DataFrames and save to .csv\n",
    "#     df_concat = pd.concat(parsed_results_dfs, ignore_index=True)\n",
    "\n",
    "#     try:\n",
    "#         df_concat.to_csv(file_name)\n",
    "#         print(f'Saved to {file_name}.')\n",
    "#     except:\n",
    "#         print(f'Error, did not save.')\n",
    "        \n",
    "#     return df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine the functions above into a single script  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 -  Using python and pandas, write code to answer the questions below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviews**\n",
    "\n",
    "Which are the 5 most reviewed businesses in your dataset?\n",
    "\n",
    "What is the highest rating received in your data set and how many businesses have that rating?\n",
    "\n",
    "What percentage of businesses have a rating greater than or  4.5?\n",
    "\n",
    "What percentage of businesses have a rating less than 3?\n",
    "\n",
    "---\n",
    "\n",
    "**Pricing**\n",
    "\n",
    "What percentage of your businesses have a price label of one dollar sign? Two dollar signs? Three dollar signs? No dollar signs?\n",
    "\n",
    "---\n",
    "\n",
    "**Returing Reviews**\n",
    "\n",
    "Return the text of the reviews for the most reviewed business. \n",
    "\n",
    "Find the highest rated business and return text of the most recent review. If multiple business have the same rating, select the business with the most reviews. \n",
    "\n",
    "Find the lowest rated business and return text of the most recent review.  If multiple business have the same rating, select the business with the least reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pagination\n",
    "\n",
    "Returning to the Yelp API, the [documentation](https://www.yelp.com/developers/documentation/v3/business_search) also provides us details regarding the API limits. These often include details about the number of requests a user is allowed to make within a specified time limit and the maximum number of results to be returned. In this case, we are told that any request has a maximum of 50 results per request and defaults to 20. Furthermore, any search will be limited to a total of 1000 results. To retrieve all 1000 of these results, we would have to page through the results piece by piece, retriving 50 at a time. Processes such as these are often refered to as pagination.\n",
    "\n",
    "Now that you have an initial response, you can examine the contents of the json container. For example, you might start with ```response.json().keys()```. Here, you'll see a key for `'total'`, which tells you the full number of matching results given your query parameters. Write a loop (or ideally a function) which then makes successive API calls using the offset parameter to retrieve all of the results (or 5000 for a particularly large result set) for the original query. As you do this, be mindful of how you store the data. \n",
    "\n",
    "**Note: be mindful of the API rate limits. You can only make 5000 requests per day, and APIs can make requests too fast. Start prototyping small before running a loop that could be faulty. You can also use time.sleep(n) to add delays. For more details see https://www.yelp.com/developers/documentation/v3/rate_limiting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Below is sample code that you can use to help you deal with the pagination parameter and bring all of the functions together.***\n",
    "\n",
    "\n",
    "***Also, something might cause your code to break while it is running. You don't want to constantly repull the same data when this happens, so you should insert the data into the database as you call and parse it, not after you have all of the data***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T22:26:50.079801Z",
     "start_time": "2021-05-10T22:26:50.066801Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a variable  to keep track of which result you are in. \n",
    "cur = 0\n",
    "\n",
    "#set up a while loop to go through and grab the result \n",
    "while cur < num and cur < 1000:\n",
    "    #set the offset parameter to be where you currently are in the results \n",
    "    url_params['offset'] = cur\n",
    "    #make your API call with the new offset number\n",
    "    results = yelp_call(url_params, api_key)\n",
    "    \n",
    "    #after you get your results you can now use your function to parse those results\n",
    "    parsed_results = parse_results(results)\n",
    "    \n",
    "    # use your function to insert your parsed results into the db\n",
    "    db_insert(parsed_results)\n",
    "    #increment the counter by 50 to move on to the next results\n",
    "    cur += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": "32",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
